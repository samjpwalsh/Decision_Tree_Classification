{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00398404",
   "metadata": {},
   "source": [
    "# Decision Tree Classification\n",
    "\n",
    "_Assignment for the University of Bath as part of MSc in Artificial Intelligence_ \n",
    "\n",
    "_Data Sources:_\n",
    "\n",
    "_weather-data - University of Bath department of Computer Science_\n",
    "\n",
    "_heart-prediction - https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset_\n",
    "\n",
    "### 1. Tree implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250dae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe5397",
   "metadata": {},
   "source": [
    "First several classes are created to represent the leaves and branches of the tree, along with a class which represents a test used to partition the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f72bee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafNode:\n",
    "    \n",
    "    def __init__(self, dataset, y_column):\n",
    "        self.output = dataset[y_column].value_counts().idxmax()\n",
    "        self.confidence = dataset[y_column].value_counts().max() / dataset[y_column].value_counts().sum()\n",
    "\n",
    "class BranchNode:\n",
    "    \n",
    "    def __init__(self, partition_test, match_branch, non_match_branch):\n",
    "        self.partition_test = partition_test\n",
    "        self.match_branch = match_branch\n",
    "        self.non_match_branch = non_match_branch\n",
    "\n",
    "class PartitionTest:\n",
    "    \n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "\n",
    "    def __repr__(self):\n",
    "        if is_discrete(self.column):\n",
    "            comparison = \"==\"\n",
    "        else:\n",
    "            comparison = \"<\"\n",
    "        return f\"Is {self.column.name} {comparison} {self.value} ?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ace566b",
   "metadata": {},
   "source": [
    "My algorithm uses a CART approach to construct a binary classification tree from a given dataset. There are a couple of implementational choices I made here. The first was to use a binary approach where each test produces a true or false result, this allows for more easily readable trees when the number of possible values of a variable is high, especially when the tree is depth-limited. The second was to use the CART algorithm as opposed to another approach such as ID3. CART is slightly less computationally expensive and performance of both algorithms is comparable.\n",
    "\n",
    "The following functions are used to partition the dataset, galculate the gini impurity and find the best partition based on the lowest weighted gini impurity for among the different tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "158e8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_discrete(column):\n",
    "    if isinstance(column.iloc[0], (np.int64, np.float64)):\n",
    "        if column.nunique() >= (len(column) * 0.1):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def partition(dataset, partition_test):\n",
    "    if is_discrete(partition_test.column):\n",
    "        match_data = dataset[dataset[partition_test.column.name] == partition_test.value]\n",
    "        non_match_data = dataset[dataset[partition_test.column.name] != partition_test.value]\n",
    "    else:\n",
    "        match_data = dataset[dataset[partition_test.column.name] < partition_test.value]\n",
    "        non_match_data = dataset[dataset[partition_test.column.name] >= partition_test.value]\n",
    "\n",
    "    return match_data, non_match_data\n",
    "\n",
    "def current_gini_impurity(dataset, y_column):\n",
    "    y_counts = dataset[y_column].value_counts()\n",
    "    gini = 1 - (np.square(y_counts / y_counts.sum())).sum()\n",
    "    return gini\n",
    "\n",
    "def weighted_gini_impurity(match_data, non_match_data, y_column):\n",
    "    y_counts = match_data[y_column].value_counts()\n",
    "    match_data_gini = 1 - (np.square(y_counts / y_counts.sum())).sum()\n",
    "    y_counts2 = non_match_data[y_column].value_counts()\n",
    "    non_match_data_gini = 1 - (np.square(y_counts2 / y_counts2.sum())).sum()\n",
    "    weighted_gini = (y_counts.sum() * match_data_gini + y_counts2.sum() * non_match_data_gini) / (y_counts.sum() + y_counts2.sum())\n",
    "    return weighted_gini\n",
    "\n",
    "def find_best_partition(dataset, y_column):\n",
    "    best_gini = None\n",
    "    best_partition_test = None\n",
    "    for column in dataset:\n",
    "        if column != y_column:\n",
    "            if is_discrete(dataset[column]):\n",
    "                for value in dataset[column].unique():\n",
    "                    test = PartitionTest(dataset[column], value)\n",
    "                    match_data, non_match_data = partition(dataset, test)\n",
    "                    gini = weighted_gini_impurity(match_data, non_match_data, y_column)\n",
    "                    if best_gini is None or gini < best_gini:\n",
    "                        best_gini = gini\n",
    "                        best_partition_test = test\n",
    "            else:\n",
    "                sorted_data = dataset.sort_values(by=column)\n",
    "                arr = np.array(sorted_data[column])\n",
    "                values = []\n",
    "                for i in range(len(arr) - 1):\n",
    "                    values.append((arr[i] + arr[i + 1]) / 2)\n",
    "                for value in values:\n",
    "                    test = PartitionTest(dataset[column], value)\n",
    "                    match_data, non_match_data = partition(dataset, test)\n",
    "                    gini = weighted_gini_impurity(match_data, non_match_data, y_column)\n",
    "                    if best_gini is None or gini < best_gini:\n",
    "                        best_gini = gini\n",
    "                        best_partition_test = test\n",
    "\n",
    "    return best_gini, best_partition_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676acee4",
   "metadata": {},
   "source": [
    "This approach can handle both discrete (numeric or non-numeric) and continuous input variables, testing whether values are equal to the test variable value when it is discrete, or less than the value when it is continuous. The next two functions below recursively grow and print the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29e4123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grow_tree(dataset, y_column, current_depth=0, max_depth=100):\n",
    "    best_gini, best_test = find_best_partition(dataset, y_column)\n",
    "    if best_gini is None or best_gini >= current_gini_impurity(dataset, y_column) or current_depth >= max_depth:\n",
    "        return LeafNode(dataset, y_column)\n",
    "    match_data, non_match_data = partition(dataset, best_test)\n",
    "    match_data, non_match_data = match_data.drop(columns=[best_test.column.name]), non_match_data.drop(columns=[best_test.column.name])\n",
    "    branch1 = grow_tree(match_data, y_column, current_depth + 1, max_depth=max_depth)\n",
    "    branch2 = grow_tree(non_match_data, y_column, current_depth + 1, max_depth=max_depth)\n",
    "    return BranchNode(best_test, branch1, branch2)\n",
    "\n",
    "def print_tree(node, spacing=\"\"):\n",
    "    if isinstance(node, LeafNode):\n",
    "        print(spacing + f\"Output = {node.output} with confidence {node.confidence}\")\n",
    "        return\n",
    "    print (spacing + str(node.partition_test))\n",
    "    print (spacing + '  --> True:')\n",
    "    print_tree(node.match_branch, spacing + \"      \")\n",
    "    print (spacing + '  --> False:')\n",
    "    print_tree(node.non_match_branch, spacing + \"      \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb8f40",
   "metadata": {},
   "source": [
    "### 2. Dataset trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e4fb6",
   "metadata": {},
   "source": [
    "The trees for the weather data and my chosen dataset (heart attack prediction) are printed below. For the heart attack prediction, I have limited the maximum depth of the tree so as to make it more readable, but this can be changed with the \"max_depth\" parameter as desired. For each leaf node, the algorithm also returns it's \"confidence\" which is simply the proportion of the prediction made by the algorithm in the leaf node data. For example, if the leaf node predicts \"Yes\" and the leaf node contains 4 \"Yes\" values and 1 \"No\" value, the confidence will be 4/5 = 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f7332b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Outlook == Overcast ?\n",
      "  --> True:\n",
      "      Output = Yes with confidence 1.0\n",
      "  --> False:\n",
      "      Is Humidity == High ?\n",
      "        --> True:\n",
      "            Is Temperature == Hot ?\n",
      "              --> True:\n",
      "                  Output = No with confidence 1.0\n",
      "              --> False:\n",
      "                  Is Wind == Weak ?\n",
      "                    --> True:\n",
      "                        Output = Yes with confidence 0.5\n",
      "                    --> False:\n",
      "                        Output = No with confidence 1.0\n",
      "        --> False:\n",
      "            Is Wind == Weak ?\n",
      "              --> True:\n",
      "                  Output = Yes with confidence 1.0\n",
      "              --> False:\n",
      "                  Is Temperature == Cool ?\n",
      "                    --> True:\n",
      "                        Output = No with confidence 1.0\n",
      "                    --> False:\n",
      "                        Output = Yes with confidence 1.0\n"
     ]
    }
   ],
   "source": [
    "weather_data = pd.read_csv(\"C:/Users/samjp/OneDrive/Desktop/Data Science Portfolio/Decision Tree Classification/Data/weather-data.csv\")\n",
    "weather_data = weather_data.drop(\"Day\", axis=1) # removing \"Day\" column as it is simply an index and not relevant to decisions\n",
    "tree = grow_tree(weather_data, \"Decision\")\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e2f34f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is thall == 2 ?\n",
      "  --> True:\n",
      "      Is caa == 0 ?\n",
      "        --> True:\n",
      "            Is trtbps < 158.0 ?\n",
      "              --> True:\n",
      "                  Output = 1 with confidence 0.9174311926605505\n",
      "              --> False:\n",
      "                  Output = 0 with confidence 0.6\n",
      "        --> False:\n",
      "            Is cp == 0 ?\n",
      "              --> True:\n",
      "                  Output = 0 with confidence 0.85\n",
      "              --> False:\n",
      "                  Output = 1 with confidence 0.78125\n",
      "  --> False:\n",
      "      Is cp == 0 ?\n",
      "        --> True:\n",
      "            Is oldpeak < 0.55 ?\n",
      "              --> True:\n",
      "                  Output = 0 with confidence 0.6363636363636364\n",
      "              --> False:\n",
      "                  Output = 0 with confidence 0.9710144927536232\n",
      "        --> False:\n",
      "            Is caa < 0.5 ?\n",
      "              --> True:\n",
      "                  Output = 1 with confidence 0.7142857142857143\n",
      "              --> False:\n",
      "                  Output = 0 with confidence 0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "heart_disease_data = pd.read_csv(\"C:/Users/samjp/OneDrive/Desktop/Data Science Portfolio/Decision Tree Classification/Data/heart-prediction.csv\")\n",
    "tree = grow_tree(heart_disease_data, \"output\", max_depth=3)\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b4fa3e",
   "metadata": {},
   "source": [
    "### 3. Performance evaluation on heart disease dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d60bca",
   "metadata": {},
   "source": [
    "In order to assess the performance of my algorithm, the functions below split the data into test and train datasets, train the model and compare it's predictions to the true output in the data, outputting overall accuracy and a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c475a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(dataset, fraction=0.1):\n",
    "    test = dataset.sample(frac=fraction, axis=0, random_state=1)\n",
    "    train = dataset.drop(index=test.index)\n",
    "\n",
    "    return test, train\n",
    "\n",
    "def predict_row_output(row, node):\n",
    "    if isinstance(node, LeafNode):\n",
    "        return node.output\n",
    "    if is_discrete(node.partition_test.column):\n",
    "        if row[1][node.partition_test.column.name] == node.partition_test.value:\n",
    "            return predict_row_output(row, node.match_branch)\n",
    "        else:\n",
    "            return predict_row_output(row, node.non_match_branch)\n",
    "    else:\n",
    "        if row[1][node.partition_test.column.name] < node.partition_test.value:\n",
    "            return predict_row_output(row, node.match_branch)\n",
    "        else:\n",
    "            return predict_row_output(row, node.non_match_branch)\n",
    "\n",
    "def predict_test_data_output(test_data, node):\n",
    "    predictions = []\n",
    "    for row in test_data.iterrows():\n",
    "        predictions.append(predict_row_output(row, node))\n",
    "    return predictions\n",
    "\n",
    "def decision_tree_accuracy(test_data, predictions, y_column):\n",
    "    comparison = test_data.assign(prediction=predictions)\n",
    "    comparison[\"match\"] = np.where(comparison[y_column] == comparison[\"prediction\"], True, False)\n",
    "    return comparison[\"match\"].value_counts()[True] / len(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d5fc768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "test_data, train_data = test_train_split(heart_disease_data)\n",
    "tree = grow_tree(train_data, \"output\", max_depth=3)\n",
    "predictions = predict_test_data_output(test_data, tree)\n",
    "accuracy = decision_tree_accuracy(test_data, predictions, \"output\")\n",
    "print(f\"Accuracy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebec4e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='prediction', ylabel='output'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEGCAYAAABmXi5tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUmUlEQVR4nO3deZyVdb3A8c93hh1BNmUZFEQFVAQ1JEUh0HJf62WKu1lqZmldK3O7luW1vNfSMovrvuIWCuYlzX0tFRNUXEAEQQVkFxhlZn73D8ZpYFgmmzMj5/d5v17zmnOe8zzPfB9ew4dnnnM4EyklJEnFr6SpB5AkNQ6DL0mZMPiSlAmDL0mZMPiSlIlmTT3AugwdM8qXD+lz6cmq5k09grROpUffFOt6zDN8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTBh8ScqEwZekTDRr6gH0rymJ4Lp9LmHe8gX88MnLaNeiLRcPPZPubbvw/rIPueDpK1i6clmd7b7YbRBn7XI8pVHC+Lcf5eYp4wA4fdAoduu+E28tfIeL/3Y1APv13pP2LTbhzjcnNOqxaeN23n1v8/ibC+nUtjnjTh8IwJWPvMsjbywkIujcthmXHLY1m7drsdp2H1dUcfz1r/FJZaKiKrHPdp347sieAPzPQzN5cuoi+ndry6WHbw3AuJfnsXhFJcft1q1xD7AIeIa/kfl63/15Z8nsmvvHbXcoL855hSP//ANenPMKx21/SJ1tSiI4e/BJ/Mfjv+To/zubL285lN7ty2jbvDUDuvTl+Ak/piRK6LPpFrQobc4BW32Je956qDEPS0Xg8J26MPrY/qst+8Ye3bn32wMZe9qOfKlvR37/+Ow627UoDa47YTvGnrYjfzp1AE9NW8TLs5aytLyCl2Z9xL3fHkhlSrw5ZznlK6sY+/KHHLXr5o11WEWlYMGPiP4R8eOIuDIirqi+vV2hvl4ONmvdiaE9dmb8tEdrlg0r+wIPTH8CgAemP8GwssF1ttu+0zbMWvoB7y2bS0VVJX+d+SzDygaTUqJ5yaof8lqWtqCyqpJj+h/MXW9OoDJVNs5BqWgM7tWeTVuvftFgk5b/vL/ik0piLdtFBG1blAJQUZWoqExAUBLBysoqUkp8vLKKZqXBdc+8x7FDutK81HPVz6Igf2oR8WNgDBDA34Hnq2/fHhHnFOJr5uCsXY7nqn/cRhVVNcs6tdqU+eWLAJhfvoiOrdrX2W6z1h2Zs3x+zf15K+azWeuOLK8o57F3/84N+/4X7y+bx0crl7Ndpz48OfvFgh+L8vGbh99lr1+/xP2T59dcqllTZVXi8D9MZs/LJjK0z6YM6rkJbVuWss92nfjqH1+hrENL2rUs5ZX3lrF3/06NfATFo1DX8E8Gdkgpray9MCIuB14FLl3bRhFxCnAKQJ9vDqbr3tsUaLyNz9AeO7OwfAlvLJzOzpv/iz8oRd3zqlT9+dbXx3Pr6+MBOGfXb3HN5Ls5uM9IhnQbyLRFM7nhtbH/5uTK3Vl7b8FZe2/B6Cdnc+vf56w1+qUlwdjTdmRJeQXfu+NN3pq7nG03b8PJe/Tg5D16AHDBuLc5Y0RP7p44l6enLaZf1zacNryssQ9no1aon4uqgB5rWd69+rG1SimNTikNTikNNvarG9ilH3uW7cI9B1/Jz3b/Hl/ougP/udt3WFC+mM6tOgDQuVUHFpYvqbPtvOUL6Nqmc839zVp35sMVC1dbp2+H3gDMXPo++/cexgXPXEGfTXvScxOfGFPDOHDHLjw0ZcF612nfqhm79mrPk1MXr7b8tfdXvRChd+dW3Pfyh/z6iG15a+5y3plfXrB5i1Ghgn8W8HBE/F9EjK7+mAA8DJxZoK9Z1P4waQyHjTuDr43/Hhc+eyUvznmVnz53FU/NfpEDthoOwAFbDV/r5ZgpC6bRs103urfdjGYlpXx5y915ao31vrXjEVwz+W6alZRSEqu+LapItGrWos7+pPqqHeRH31hIny6t6qyzYNlKlpRXAFC+sopnpy+ps95vH53Fd0f2pKIqUZVW/XxaEkH5Sp9r+lcU5JJOSmlCRPQFhgBlrLp+Pwt4PiWfDWxIN08Zx8/3OJOD+oxgzvL5nPf0bwDo0qoj5wz5Fmc/8SsqUxWXv3gDv/7STygtKeH+tx9j+pJZNfsYXjaYKQve5sPyVWf9r8x/i5v3+yVTF81k6qKZTXFY2gidfc9U/v7OEhYtr2Dk5RM5Y0RPnpi6iOkfllMS0KNDS/7zwK0AmLv0Ey4Y9zZ/PKY/8z5ayU/unUZVVaIqwX47dGJE3441+/3r6wsY0KNtzcs5B/XchEOvnkTfrm3o361tkxzrxipSShteqwkMHTPq8zmYsvdkVfOmHkFap9Kjb1rbi6EAX4cvSdkw+JKUCYMvSZkw+JKUCYMvSZkw+JKUCYMvSZkw+JKUCYMvSZkw+JKUCYMvSZkw+JKUCYMvSZkw+JKUCYMvSZkw+JKUCYMvSZkw+JKUCYMvSZkw+JKUCYMvSZkw+JKUCYMvSZkw+JKUCYMvSZkw+JKUCYMvSZkw+JKUCYMvSZkw+JKUCYMvSZkw+JKUCYMvSZkw+JKUCYMvSZmoV/Aj4sz6LJMkfX7V9wz/hLUsO7EB55AkFViz9T0YEaOAo4GtImJcrYfaAfMLOZgkqWGtN/jAM8D7QBfgf2otXwpMKtRQkqSGt97gp5RmADOA3RtnHElSoWzoDB+AiFgKpOq7LYDmwLKUUvtCDSZJalj1Cn5KqV3t+xFxGDCkEANJkgrjM70OP6V0L7BXw44iSSqk+l7S+WqtuyXAYP55iUeStBGoV/CBg2vdrgDeAQ5t8GkkSQVT32v4JxV6EElSYdX3rRX6RMT4iJgXEXMj4r6I6FPo4SRJDae+T9reBtwJdAd6AHcBtxdqKElSw6tv8COldHNKqaL64xZ80laSNir1fdL20Yg4BxjDqtAfCfw5IjoBpJQWNPRgZ4ya2NC7lBpEs9M6NvUI0jqlo9f9WH2Df2T151PXWP4NVv0D4PV8Sfqcq2/wt0splddeEBGt1lwmSfr8qu81/GfquUyS9Dm1offD7waUAa0jYmcgqh9qD7Qp8GySpAa0oUs6+7LqN1v1BC6vtXwpcG6BZpIkFcCG3g//RuDGiPhaSumeRppJklQA9X3SdkBE7LDmwpTSzxp4HklSgdQ3+B/Vut0KOAiY0vDjSJIKpb5vnlb799kSEf8NjFvH6pKkz6HP9AtQWPUKHf+zlSRtROr7C1Am88/3zikBNgcuLtRQkqSGV99r+AcBHYFhQAfggZTSi4UaSpLU8Op7SedQ4GagC9AcuD4ivluwqSRJDa6+Z/jfBHZLKS0DiIhfAs8Cvy3UYJKkhlXv98MHKmvdr+Sfb7MgSdoI1PcM/3rgbxExtvr+YcC1BZlIklQQ9X0d/uUR8RiwJ6vO7E9KKb1UyMEkSQ2rvmf4pJQmAv4aKknaSH3W/3glSdrIGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGHxJyoTBl6RMGPyNWPd9h3HQ6xM4+K0H2f7H31rrOl+44jwOfutB9n95HB133h6All068uUnb+OAyePpeejeNesOv/f3tO6+eaPMruJUEiVMPPdGxp/+3zXLzhhxBK9fdAevXHAbvzz8jDrb9O26JS+de1PNx+LLH+bMvY4E4NLDvsPL593CjSdcWLP+sUP243sjv174gylCzZp6AH02UVLC4Ksu5JGvnMSKWXPY9/m7mTXuEZZMmVazTo/9h9Nu296M33YfOn9xELtefREP7vZ1eo06iOk3jmXGmAcYOeEaZt33MGUHjWTBxFdZ8f7cJjwqbezO3OtIpnzwDu1btQVgRN9dOHTQcAb+/Fg+qVjJZu061tnmzTkz2fmS44FV/2DM/q/xjP3H47Rv1ZahW+/IoF8cyy0n/ZQBPbZm6rxZnLj7gez327Ma87CKhmf4G6nOQwby0dQZLJs+i6qVK5kx5s+rna0DlB26N9NvuheA+X97mRYd2tOq22ZUraygtHUrSlu2IFVVEaWl9DvrBKZcdm0THImKRVmHzThwwFCueXpczbJvD/8ql/7lJj6pWAnAvKUL17uPvfsPZtqHs5m54AOqUqJFaXMAWjdvycrKCn74lWO48tE7qaiqLNyBFDGDv5FqXdaVZe9+UHN/+aw5tCnruto6bcq6sny1dT6gTVlXZtw2nu777smICdcw+aLfsu3pRzP9pnupXFHeaPOr+PzmiO/zo7G/o6oq1Szru/mWDNtmEM/96Foe+/7vGdxru/Xu46jBX+H25x8E4KOPl3PPS4/y0rk3MX3+eyxe8RG79tqecZOeLOhxFLNGD35EnLSex06JiBci4oVHWNSIU22EIuosSinVa52VSz7i8YNO5S+7fo0FE1+j7KARvHvPgwwZfTF73nUFXXbbqUBDq1gdOGAP5i5dyMSZb6y2vFlpKR3btGe3X53MD//0O+785i/WuY/mpc04ZOAw7pr4SM2yyx66hZ0vOZ6z77mSiw85lQvHj+bkPQ7hjm/+nPP2X2dKtA5NcYb/03U9kFIanVIanFIavBcdGnGkjc+KWR/QdotuNffb9OzKivdWv/6+fNYHtFltnW511tnxwu/w6i/+QK9RB7LgxVd57hvnMuiSHxR2eBWdPbYeyCEDhzH952MZc/LF7NVvMDefeBGzFs7lTy89BsDzM16jKlXRZZMOa93H/jvszsSZbzB36YI6j+3Usy8Ab86dyfFf3J8jrzmfAT36sM1mWxTqkIpSQYIfEZPW8TEZ6LrBHWiD5j8/mXbb9qZt756UNG9Or6MOZPa4R1ZbZ/a4R9jq+MMA6PzFQaxcvJTyD+bVPN5um1607rE5c594nmZtWpOqqiBBaasWjXkoKgLn3nc1W5x7CFudfzhHXXsBj7zxAsfdcBH3vvwEe/X7AgDbbr4FLUqb8+FHi9a6j1G77sPtLzy41scuPuQULhw/mualzSgtKQWgKlXRpkXLghxPsSrUq3S6AvsCaz5DE8AzBfqaWUmVlbxwxs8Y+ZdriNJS3r7uHha/NpVtTj0KgKl/HMN7DzxOjwO+xMFTH6Jy+QqeO+nc1fYx8BffZ9J5vwbgndvvZ/i9V9HvzOOZfOGVjX48Kk7XPTOe6447n8kX3MonFRWccNPPAOi+aReuOfZcDrxq1U+TrZu35Cv9h3DqrZfW2cehg4bz/IwpvL/4QwCefXsyk86/hUmzpzFp9tTGO5giEHWu+zbETiOuBa5PKT21lsduSykdvaF93Bb9Gn4wqQEcc1rdlxZKnxfp6ufqPnlXrSBn+Cmlk9fz2AZjL0lqeL4sU5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyYfAlKRMGX5IyESmlpp5BjSAiTkkpjW7qOaQ1+b3ZeDzDz8cpTT2AtA5+bzYSgy9JmTD4kpQJg58Pr5Hq88rvzUbik7aSlAnP8CUpEwZfkjJh8ItcROwXEW9ExNSIOKep55E+FRHXRcTciHilqWfJhcEvYhFRClwF7A9sD4yKiO2bdiqpxg3Afk09RE4MfnEbAkxNKb2dUvoEGAMc2sQzSQCklJ4AFjT1HDkx+MWtDHi31v1Z1cskZcjgF7dYyzJfhytlyuAXt1nAFrXu9wTea6JZJDUxg1/cnge2jYitIqIFcBQwrolnktREDH4RSylVAGcAfwGmAHemlF5t2qmkVSLiduBZoF9EzIqIk5t6pmLnWytIUiY8w5ekTBh8ScqEwZekTBh8ScqEwZekTBh8aT0iYkRE3F99+5D1veNoRHSIiNNr3e8REXc3xpxSffiyTGUpIkpTSpX1WG8EcHZK6aB6rNsbuD+lNODfHlAqAM/wVXQiondEvB4RN0bEpIi4OyLaRMQ7EXFhRDwFHBER+0TEsxExMSLuiohNqrffr3r7p4Cv1trviRHxu+rbXSNibES8XP0xFLgU2Doi/hERl1XP8Ur1+q0i4vqImBwRL0XEyFr7/FNETIiItyLiV43956V8GHwVq37A6JTSQGAJ8OmllvKU0p7AX4HzgS+nlHYBXgB+EBGtgP8FDgaGAd3Wsf8rgcdTSoOAXYBXgXOAaSmlnVJKP1xj/e8ApJR2BEYBN1Z/LYCdgCOBHYEjI2ILpAIw+CpW76aUnq6+fQuwZ/XtO6o/78aqXwrzdET8AzgB6AX0B6anlN5Kq6533rKO/e8FXA2QUqpMKS3ewDx7AjdXr/86MAPoW/3YwymlxSmlcuC16jmkBtesqQeQCmTNJ6c+vb+s+nMAD6WURtVeKSJ2Wsu2DWFtb1X9qY9r3a7Ev5cqEM/wVay2jIjdq2+PAp5a4/HngD0iYhuA6mv8fYHXga0iYuta267Nw8C3q7ctjYj2wFKg3TrWfwI4pnr9vsCWwBv/8lFJ/waDr2I1BTghIiYBnai+/PKplNI84ETg9up1ngP6V19WOQX4c/WTtjPWsf8zgZERMRl4EdghpTSfVZeIXomIy9ZY//dAafX6dwAnppQ+RmpEvixTRceXR0pr5xm+JGXCM3xJyoRn+JKUCYMvSZkw+JKUCYMvSZkw+JKUif8HO/FMdp6K85EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparison = test_data.assign(prediction=predictions)\n",
    "confusion_matrix = pd.crosstab(comparison[\"output\"], comparison[\"prediction\"])\n",
    "sn.heatmap(confusion_matrix/len(test_data), annot=True, fmt=\".1%\", cbar=False, cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1aac52",
   "metadata": {},
   "source": [
    "Finally, the code below runs k-fold cross validation to assess the performance of the algorithm over 10 different test/train splits, to get a better idea of how accurate the algorithm is more generally. The output is the accuracy on each split, along with the average accuracy over all 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35c8eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(dataset, y_column, max_depth=100, k=10):\n",
    "    accuracy_list = []\n",
    "    sample_list = [i for i in range(len(dataset))]\n",
    "    while sample_list != []:\n",
    "        sample = random.sample(sample_list, min((-(-len(dataset) // k)), len(sample_list)))\n",
    "        for num in sample:\n",
    "            sample_list.remove(num)\n",
    "        test_data = dataset.iloc[sample]\n",
    "        train_data = dataset.drop(index=test_data.index)\n",
    "        tree = grow_tree(train_data, y_column, max_depth=max_depth)\n",
    "        predictions = predict_test_data_output(test_data, tree)\n",
    "        accuracy_list.append(decision_tree_accuracy(test_data, predictions, y_column))\n",
    "    average_accuracy = np.mean(accuracy_list)\n",
    "    return accuracy_list, average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cf89317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on each split = [0.7419354838709677, 0.8064516129032258, 0.967741935483871, 0.7096774193548387, 0.8709677419354839, 0.9032258064516129, 0.7096774193548387, 0.6129032258064516, 0.8064516129032258, 0.875]\n",
      "Average accuracy = 0.8004032258064516\n"
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "acc_list, ave_acc = cross_validation(heart_disease_data, \"output\", max_depth=3)\n",
    "print(f\"Accuracy on each split = {acc_list}\")\n",
    "print(f\"Average accuracy = {ave_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
